\section{Introduction}
Throughout the history of mankind, inventors have been dedicated to create machines that can think. And the invention of electronic computer has sharply shortened the distance towards that great aspiration and several approaches towards artificial intelligence (AI) have been proposed. The idea of composing several simpler functions to form a mathematical function mapping some set of input values to output values to create an AI was first proposed back in the 1940s\cite{mcculloch1943logical}. Such approach, now known as \emph{deep learning}, was presumed to be preciously valuable since neuroscience suggested that a single deep learning algorithm may be able to solve many different tasks\cite{von2000visual}. It is even presumed now to be the only viable approach towards building AI systems that can operate in complicated, real-world environments\cite{dlbook}. With the advent of general purpose GPUs, deep learning works perfectly with large models and large datasets. And the combination of deep learning and big data has dramatically improved the state-of-the-art of speech recognition, computer vision, motion planning, natural language processing and other fields\cite{lecun2015deep}. Deep learning has now outperformed competing AI systems\cite{dlbook}.

Convolutional neural networks(CNN)\cite{lecun1989generalization} employ convolution operation in at least one layer of an neural network, which reduces the scale of matrix multiplications and hence brings about the capability of processing larger input. It has been proved potent in many fields of artificial intelligence especially in computer vision, where it was first used to read checks\cite{lecun1998gradient} and is now the forerunner of many contests\cite{krizhevsky2012imagenet}.

We exploited CNN to build an image classification service that can classify images of four tourist attractions in Tsinghua University: the Auditorium, the Old Gate, the Main Building and Tsinghua School. Even with a limited set of training data we have achieved an accuracy no less than 80 percent. With more labeled training data the model can be extended to classify more landmarks and have better accuracy, which can be later embedded in intelligent applications such as tour guide systems and augmented reality applications.
